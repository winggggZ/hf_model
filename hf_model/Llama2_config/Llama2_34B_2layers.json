{
  "vocab_size":32000,
  "hidden_size":6656,
  "intermediate_size":26624,
  "num_hidden_layers":2,
  "num_attention_heads":32,
  "seq_len": 128
}